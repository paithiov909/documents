---
title: Rでdoc2vecしたい
tags: R doc2vec gensim
author: paithiov909
slide: false
---
## この記事について

2018年の2月くらいに書いたブログ記事を移動してきたものです。Python書けないマンなので{PythonInR}でRからgensimを呼んでdoc2vecしています。

2019年現在では、RからPythonを呼びたいときは{reticulate}を使うのがよいと思われます。また、文書のベクトル表現は{textTinyR}パッケージを使っても得ることができるようになっています（[参考](https://rdrr.io/cran/textTinyR/man/Doc2Vec.html)）。

## テキストの準備

テキストを用意する。

`gensim.models.doc2vec.TaggedDocument()`を呼ぶとメモリをもりもり消費して辛いので、分かち書きされたテキストファイルを用意して`gensim.models.doc2vec.TaggedLineDocument()`に食わせるのがおすすめ。

```{R}
MECABRC = file.path(getwd(), "config/mecabrc")

chr2Owakati <- function(chr, path_to, rcpath = MECABRC) {
    desc <- file.path(tempdir(), "temp.txt")
    tf <- file(desc, open = "w+", encoding = "shift_jis")
    write(chr, file = tf, sep = "\r\n")
    system(command = paste("mecab", desc, "-r", rcpath, "-o", path_to, "-Owakati"))
    close(tf)
}

chr <- readLines("target.txt")
path_to <- file.path(getwd(), "cache", "sample.txt")
chr2Owakati(chr, path_to)
```

こんな感じで好きにやってください。

## doc2Vec

Windows10でCドライブ直下にAnacondaを入れている。Windowsなのでgensimを読みこんだときに何かのwarningが出るけど気にしない。

```{R}
library(PythonInR)
library(tidyverse)

sample <- readLines("cache/sample.txt")

#### Load gensim ####
pyConnect(pythonExePath = "C:\\Anaconda3\\python.exe")
pyImport("numpy", as = "np")
pyImport("gensim", as = "gensim")
pyImport("doc2vec", from = "gensim.models")
pyImport("TaggedLineDocument", from = "gensim.models.doc2vec")

bindingTaggedLine <- function(chrvec)
{
    tmp <- tempfile(fileext = ".txt")
    chrvec %>%
        iconv(from = "shift_jis", to = "UTF-8") %>%
        write_lines(path = tmp)

    corpus <- TaggedLineDocument(tmp)
    return(corpus)
}

#### Modeling ####
fname <- "sample"
len <- length(sample)

corpus <- bindingTaggedLine(sample)

model <- doc2vec$Doc2Vec(
    dm = 1,
    size = 300L,
    window = 5L,
    min_count = 1L,
    iter = 50L
)

model$build_vocab(corpus)
model$train(
    corpus,
    total_examples = len,
    epochs = model$iter
)

# doc2vecのモデルのまま保存してもうれしくないので、
# word2vecの形式で保存する
model$save_word2vec_format(
    fname = file.path("cache", paste0("doc2vec_", fname, ".model")),
    doctag_vec = TRUE
)
```

## infer_vectorの取得

infer_vectorの戻り値は`obj: numpy.ndarray`

ちょっとどうしようもないのでvstackで積み上げてそのまま保存する。

```{R}
#### Get infer_vector in model above ####

text <- c("何か こういう 感じ の UTF-8 の テキスト", "なんでも いい")

pySet("model", model)
pyExec(code = "sentences = []")
l <- lapply(text, function(chr){
    pySet("str", paste0(chr, collapse = " "))
    pyExec(code = "sentences.append(gensim.utils.simple_tokenize(str))")
})

pyExec(code = '

vecs = np.empty([1,300])
for sentence in sentences:
    vecs = np.vstack((vecs, model.infer_vector(sentence)))
np.save("cache/test.npy", vecs)

')

remove(l)
```

## Rでモデルを読み込む

word2vecフォーマットのファイルは、最初の行に行数と次数が書いてあってあとは各値を半角スペースで区切っているだけの単純なテーブルである。

はじめの方には単語のベクトルがあって、文書のベクトルは後ろの方にある。文書のベクトルだけ欲しい場合、文書ベクトルの列名は`*dt`で始まるので、それらの行だけ取ってくればいい。

```{R}
df <- read_table2("cache/doc2vec_free.model", col_names = FALSE, skip = 1L) %>%
    filter(stringr::str_detect(X1, "\\*dt"))
```

infer_vectorを保存したnpyファイルは[{RcppCNpy}](http://dirk.eddelbuettel.com/code/rcpp.cnpy.html)パッケージのnpyLoad()で読める。最初の行はダミーだったので2行目以降を取ればいい。

```{R}
library(RcppCNpy)
npy <- npyLoad("cache/test.npy")
npy <- npy[2:nrow(npy),]
```

