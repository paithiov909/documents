---
ID: a47a097836e8a9ec12ef
Title: R（quanteda）によるテキスト解析
Tags: R,自然言語処理,NLP,テキストマイニング
Author: Kato Akiru
Private: false
---

## Googleドキュメントの読み込み

これまで自分が書いてきた文章について、テキスト解析をしてみます。ここで分析している文章はnoteで読むことができます。

> [さちこ｜note](https://note.com/shinabitanori)

これまでに書いた文章はいくつかの場所にバックアップを取っていて、Googleドキュメントにもバックアップがあります。今回はそれらをgoogledriveで取得し、readtextで読み込みます。

`googledrive::drive_download`はディレクトリごとダウンロードしたりはできないようなので、特定のディレクトリにあるファイルのリスト（dribble）を`dplyr::rowwise`で行ごとに渡して`dplyr::do`のなかでダウンロードしています。



```r
aquarium <- googledrive::drive_ls("Archives/aquarium/") %>%
  dplyr::rowwise() %>%
  dplyr::do(
    googledrive::drive_download(
      googledrive::as_id(.$id),
      path = file.path(tempdir(), .$name),
      overwrite = TRUE,
      verbose = FALSE
    )
  )
shinabitanori <- googledrive::drive_ls("Archives/shinabitanori/") %>%
  dplyr::rowwise() %>%
  dplyr::do(
    googledrive::drive_download(
      googledrive::as_id(.$id),
      path = file.path(tempdir(), .$name),
      overwrite = TRUE,
      verbose = FALSE
    )
  )
```

ダウンロードしたdocxファイルのリストをデータフレームとして持っておきます。文章は公開されている場所などに応じて２つのディレクトリに分けて保存されています。ここでは、この保存されているディレクトリを文書の変数として持つようにします。


```r
df <- list("aquarium", "shinabitanori") %>%
  purrr::map_dfr(~
  dplyr::mutate(rlang::eval_tidy(sym(.)), doc = .)) %>%
  dplyr::select(doc, name, local_path) %>%
  tibble::rowid_to_column()

head(df, 8L)
#> # A tibble: 8 x 4
#> # Rowwise: 
#>   rowid doc          name        local_path                                              
#>   <int> <chr>        <chr>       <chr>                                                   
#> 1     1 aquarium     nfe7f3c14d~ "C:\\Users\\user\\AppData\\Local\\Temp\\RtmpScZk2L/nfe7~
#> 2     2 aquarium     nd8e254523~ "C:\\Users\\user\\AppData\\Local\\Temp\\RtmpScZk2L/nd8e~
#> 3     3 aquarium     na40ed6bf4~ "C:\\Users\\user\\AppData\\Local\\Temp\\RtmpScZk2L/na40~
#> 4     4 aquarium     n64f6fad28~ "C:\\Users\\user\\AppData\\Local\\Temp\\RtmpScZk2L/n64f~
#> 5     5 aquarium     n665b550f2~ "C:\\Users\\user\\AppData\\Local\\Temp\\RtmpScZk2L/n665~
#> 6     6 shinabitano~ n5c07b0f3f~ "C:\\Users\\user\\AppData\\Local\\Temp\\RtmpScZk2L/n5c0~
#> 7     7 shinabitano~ n4c2b3e09c~ "C:\\Users\\user\\AppData\\Local\\Temp\\RtmpScZk2L/n4c2~
#> 8     8 shinabitano~ nb9fff6994~ "C:\\Users\\user\\AppData\\Local\\Temp\\RtmpScZk2L/nb9f~
```

## 形態素解析

[この自作パッケージ](https://github.com/paithiov909/RcppKagome)を使っています。結果をquantedaのコーパスオブジェクトとして格納して、いろいろ試していきます。


```r
normalize <- function(str) {
  str %>%
    stringr::str_replace_all("\u2019", "\'") %>%
    stringr::str_replace_all("\u201d", "\"") %>%
    stringr::str_replace_all("[\u02d7\u058a\u2010\u2011\u2012\u2013\u2043\u207b\u208b\u2212]", "-") %>%
    stringr::str_replace_all("[\ufe63\uff0d\uff70\u2014\u2015\u2500\u2501\u30fc]", enc2utf8("\u30fc")) %>%
    stringr::str_replace_all("[~\u223c\u223e\u301c\u3030\uff5e]", "~") %>%
    stringr::str_remove_all("[[:punct:]]+") %>%
    stringr::str_remove_all("[[:blank:]]+") %>%
    stringr::str_remove_all("[[:cntrl:]]+") %>%
    return()
}

corp <- df %>%
  dplyr::rowwise() %>%
  dplyr::do(
    readtext::readtext(
      .$local_path,
      docvarsfrom = "filenames",
      docvarnames = c("name")
    )
  ) %>%
  dplyr::bind_rows() %>%
  dplyr::left_join(
    dplyr::select(df, rowid, doc, name),
    by = "name"
  ) %>%
  dplyr::mutate(text = normalize(text))

corp <- corp %>%
  dplyr::pull("text") %>%
  RcppKagome::kagome() %>%
  RcppKagome::prettify() %>%
  RcppKagome::pack() %>%
  dplyr::bind_cols(corp) %>%
  quanteda::corpus(text_field = "Text")
```

## ワードクラウド

ストップワードとして`rtweet::stopwordslangs`を利用しています。


```r
stopwords <- rtweet::stopwordslangs %>%
  dplyr::filter(lang == "ja") %>%
  dplyr::filter(p >= .98) %>%
  dplyr::pull(word)

corp %>%
  quanteda::tokens(what = "word") %>%
  quanteda::tokens_remove(stopwords, valuetype = "fixed") %>%
  quanteda::dfm(groups = "doc") %>%
  quanteda::dfm_trim(min_termfreq = 3L) %>%
  quanteda::textplot_wordcloud(comparison = TRUE, color = viridis::cividis(3))
```

![wordcloud-1.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/228173/77d1c0b1-c4b2-6e0b-1cfe-2ffdb32c3fb0.png)


## 出現頻度の集計


```r
corp %>%
  quanteda::tokens(what = "word") %>%
  quanteda::tokens_remove(stopwords, valuetype = "fixed") %>%
  quanteda::dfm() %>%
  quanteda::dfm_weight("prop") %>%
  quanteda::textstat_frequency(groups = "doc") %>%
  dplyr::top_n(-16L, rank) %>%
  ggpubr::ggdotchart(
    x = "feature",
    y = "frequency",
    group = "group",
    color = "group",
    rotate = TRUE
  ) +
  ggplot2::theme_bw()
```

![stats-1.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/228173/75d3bac9-0b16-7786-4b9e-ed369dfce1bc.png)


## Keyness

aquariumグループの文書とその他の対照を見ています。


```r
corp %>%
  quanteda::tokens(what = "word") %>%
  quanteda::tokens_remove(stopwords, valuetype = "fixed") %>%
  quanteda::dfm(groups = "doc") %>%
  quanteda::textstat_keyness(target = "aquarium") %>%
  quanteda::textplot_keyness()
```

![keyness-1.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/228173/4217b6ed-5715-6f0b-fe8f-1cbad1f39681.png)


## 対応分析


```r
corp %>%
  quanteda::tokens(what = "word") %>%
  quanteda::tokens_remove(stopwords, valuetype = "fixed") %>%
  quanteda::dfm() %>%
  quanteda::dfm_weight(scheme = "prop") %>%
  quanteda.textmodels::textmodel_ca() %>%
  quanteda.textmodels::textplot_scale1d(
    margin = "documents",
    groups = quanteda::docvars(corp, "doc")
  )
```

![ca-1.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/228173/6c39e449-0f73-7670-b78e-a799acdf22ec.png)


## 共起ネットワーク


```r
corp %>%
  quanteda::tokens(what = "word") %>%
  quanteda::tokens_remove(stopwords, valuetype = "fixed") %>%
  quanteda::dfm(groups = "doc") %>%
  quanteda::dfm_trim(min_termfreq = 20L) %>%
  quanteda::fcm() %>%
  quanteda::textplot_network(min_freq = .8)
#> Warning: ggrepel: 1 unlabeled data points (too many overlaps). Consider increasing
#> max.overlaps
```

![network-1.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/228173/14a3aab4-c950-9a30-1c2f-2abf320a539f.png)


## クラスタリング

マンハッタン距離、ward法（ward.D2）です。


```r
d <- corp %>%
  quanteda::tokens(what = "word") %>%
  quanteda::tokens_remove(stopwords, valuetype = "fixed") %>%
  quanteda::dfm() %>%
  quanteda::dfm_weight(scheme = "prop") %>%
  quanteda::textstat_dist(method = "manhattan") %>%
  as.dist() %>%
  hclust(method = "ward.D2") %>%
  ggdendro::dendro_data(type = "rectangle") %>%
  purrr::list_modify(
    labels = dplyr::bind_cols(
      .$labels,
      names = quanteda::docvars(corp, "name"),
      doc = quanteda::docvars(corp, "doc")
    )
  )

ggplot2::ggplot(ggdendro::segment(d)) +
  ggplot2::geom_segment(aes(x = x, y = y, xend = xend, yend = yend)) +
  ggplot2::geom_text(ggdendro::label(d), mapping = aes(x, y, label = names, colour = doc, hjust = 0), size = 3) +
  ggplot2::coord_flip() +
  ggplot2::scale_y_reverse(expand = c(.2, 0)) +
  ggdendro::theme_dendro()
```

![clust-1.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/228173/72d27bb4-1318-943b-f611-5f729287a9f8.png)


## LDA（Latent Dirichlet Allocation）


```r
dtm <- corp %>%
  quanteda::tokens(what = "word") %>%
  quanteda::tokens_remove(stopwords, valuetype = "fixed") %>%
  quanteda::dfm() %>%
  quanteda::dfm_tfidf()

features <- corp %>%
  quanteda::tokens(what = "word") %>%
  quanteda::tokens_remove(stopwords, valuetype = "fixed") %>%
  quanteda::dfm(groups = "name") %>%
  quanteda::ntoken()

m <- dtm %>%
  as("dgCMatrix") %>%
  textmineR::FitLdaModel(k = 3, iterations = 200, burnin = 175)

m$phi %>%
  textmineR::GetTopTerms(15L) %>%
  knitr::kable()
```



|t_1      |t_2      |t_3        |
|:--------|:--------|:----------|
|ゴリラ   |グループ |因子       |
|ポエジー |条例     |x          |
|批評     |感情     |価値       |
|行間     |文節     |運動会     |
|詩       |語り     |中止       |
|主義     |物語     |文         |
|テクスト |文体     |花水木     |
|ルール   |v        |研究       |
|孤独     |加藤     |天気       |
|評       |演技     |対         |
|効果     |役割     |並列       |
|脅迫     |自己     |さよなら   |
|意図     |治郎     |エンゲージ |
|硬派     |語り口   |メン       |
|隠喩     |文書     |q          |

LDAvisで可視化してみます。ただ、LDAvisはもうしばらくメンテナンスされていないパッケージで、ちょっと挙動があやしいところがあります。たとえば、デフォルトロケールがCP932であるWindows環境の場合、`LDAvis::createJSON`で書き出されるラベル（vocab）のエンコーディングがそっちに引きずられてCP932になってしまうため、ブラウザで表示したときにラベルが文字化けします。書き出されたlda.jsonをUTF-8に変換すれば文字化けは解消されるので、とりあえずあとから変換して上書きするとよいです。


```r
LDAvis::createJSON(
  phi = m$phi,
  theta = m$theta,
  doc.length = features,
  vocab = stringi::stri_enc_toutf8(dtm @ Dimnames$features),
  term.frequency = quanteda::colSums(dtm)
) %>%
  LDAvis::serVis(open.browser = FALSE, out.dir = file.path(getwd(), "cache"))
#> Warning in dir.create(out.dir): 'C:\Users\user\Documents\cache' はすでに存在します
#> Loading required namespace: servr

readr::read_lines_raw(file.path(getwd(), "cache", "lda.json")) %>%
  iconv(from = "CP932", to = "UTF-8") %>%
  jsonlite::parse_json(simplifyVector = TRUE) %>%
  jsonlite::write_json(file.path(getwd(), "cache", "lda.json"), dataframe = "columns", auto_unbox = TRUE)
```

![ldavis_screenshot.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/228173/b34ce7d2-60e9-7cd3-a514-7c51e5dfa0c4.png)


## GloVe


```r
toks <- corp %>%
  quanteda::tokens(what = "word") %>%
  as.list() %>%
  text2vec::itoken()

vocab <- toks %>%
  text2vec::create_vocabulary() %>%
  text2vec::prune_vocabulary(term_count_min = 5L)

vect <- text2vec::vocab_vectorizer(vocab)

tcm <- text2vec::create_tcm(
  it = toks,
  vectorizer = vect,
  skip_grams_window = 5L
)

glove <- text2vec::GlobalVectors$new(
  rank = 50,
  x_max = 15L
)

wv <- glove$fit_transform(
  x = tcm,
  n_iter = 10L
) %>%
  as.data.frame(stringsAsFactors = FALSE) %>%
  tibble::as_tibble(.name_repair = "minimal", rownames = NA)
#> INFO  [15:28:47.114] epoch 1, loss 0.2035 
#> INFO  [15:28:47.253] epoch 2, loss 0.0992 
#> INFO  [15:28:47.365] epoch 3, loss 0.0784 
#> INFO  [15:28:47.461] epoch 4, loss 0.0661 
#> INFO  [15:28:47.560] epoch 5, loss 0.0574 
#> INFO  [15:28:47.661] epoch 6, loss 0.0508 
#> INFO  [15:28:47.756] epoch 7, loss 0.0456 
#> INFO  [15:28:47.880] epoch 8, loss 0.0414 
#> INFO  [15:28:47.985] epoch 9, loss 0.0379 
#> INFO  [15:28:48.083] epoch 10, loss 0.0350
```

Rtsneで次元を減らして可視化します。


```r
getRtsneAsTbl <- function(tbl, dim = 2, perp = 30) {
  tsn <- tbl %>% Rtsne::Rtsne(dim = dim, perplexity = perp)
  tsny <- tsn$Y
  rownames(tsny) <- row.names(tbl)
  tsny <- as.data.frame(tsny, stringsAsFactors = FALSE)
  return(tibble::as_tibble(tsny, .name_repair = "minimal", rownames = NA))
}

vec <- vocab %>%
  dplyr::anti_join(
    y = tibble::tibble(words = stopwords),
    by = c("term" = "words")
  ) %>%
  dplyr::arrange(desc(term_count)) %>%
  head(100) %>%
  dplyr::left_join(tibble::rownames_to_column(wv), by = c("term" = "rowname")) %>%
  tibble::column_to_rownames("term") %>%
  dplyr::select(V1, V2)

dist <- proxy::dist(x = vec, y = vec, method = "Euclidean", diag = TRUE)
clust <- kmeans(x = dist, centers = 5)
vec <- getRtsneAsTbl(vec, perp = 2) %>%
  tibble::rownames_to_column() %>%
  dplyr::mutate(cluster = as.factor(clust$cluster))

vec %>%
  ggplot2::ggplot(aes(x = V1, y = V2, colour = cluster)) +
  ggplot2::geom_point() +
  ggrepel::geom_text_repel(aes(label = rowname)) +
  ggplot2::theme_light()
#> Warning: ggrepel: 1 unlabeled data points (too many overlaps). Consider increasing
#> max.overlaps
```

![lda_2-1.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/228173/bc432368-de96-05ac-a4d7-b56a84dc5f36.png)


## セッション情報


```r
sessioninfo::session_info()
#> - Session info ------------------------------------------------------------------------
#>  setting  value                       
#>  version  R version 4.0.3 (2020-10-10)
#>  os       Windows 10 x64              
#>  system   x86_64, mingw32             
#>  ui       RStudio                     
#>  language (EN)                        
#>  collate  Japanese_Japan.932          
#>  ctype    Japanese_Japan.932          
#>  tz       Asia/Tokyo                  
#>  date     2021-01-20                  
#> 
#> - Packages ----------------------------------------------------------------------------
#>  ! package             * version   date       lib source        
#>    abind                 1.4-5     2016-07-21 [1] CRAN (R 4.0.0)
#>    askpass               1.1       2019-01-13 [1] CRAN (R 4.0.2)
#>    assertthat            0.2.1     2019-03-21 [1] CRAN (R 4.0.2)
#>    backports             1.2.1     2020-12-09 [1] CRAN (R 4.0.3)
#>    broom                 0.7.3     2020-12-16 [1] CRAN (R 4.0.3)
#>    car                   3.0-10    2020-09-29 [1] CRAN (R 4.0.2)
#>    carData               3.0-4     2020-05-22 [1] CRAN (R 4.0.0)
#>    cellranger            1.1.0     2016-07-27 [1] CRAN (R 4.0.2)
#>    cli                   2.2.0     2020-11-20 [1] CRAN (R 4.0.3)
#>    coda                  0.19-4    2020-09-30 [1] CRAN (R 4.0.2)
#>    codetools             0.2-16    2018-12-24 [2] CRAN (R 4.0.3)
#>    colorspace            2.0-0     2020-11-11 [1] CRAN (R 4.0.3)
#>    crayon                1.3.4     2017-09-16 [1] CRAN (R 4.0.2)
#>    curl                  4.3       2019-12-02 [1] CRAN (R 4.0.2)
#>    data.table            1.13.6    2020-12-30 [1] CRAN (R 4.0.3)
#>    DBI                   1.1.1     2021-01-15 [1] CRAN (R 4.0.3)
#>    dbplyr                2.0.0     2020-11-03 [1] CRAN (R 4.0.3)
#>    digest                0.6.27    2020-10-24 [1] CRAN (R 4.0.3)
#>    dplyr               * 1.0.3     2021-01-15 [1] CRAN (R 4.0.3)
#>    ellipsis              0.3.1     2020-05-15 [1] CRAN (R 4.0.2)
#>    evaluate              0.14      2019-05-28 [1] CRAN (R 4.0.2)
#>    fansi                 0.4.2     2021-01-15 [1] CRAN (R 4.0.3)
#>    farver                2.0.3     2020-01-16 [1] CRAN (R 4.0.2)
#>    fastmatch             1.1-0     2017-01-28 [1] CRAN (R 4.0.0)
#>    float                 0.2-4     2020-04-22 [1] CRAN (R 4.0.0)
#>    forcats             * 0.5.0     2020-03-01 [1] CRAN (R 4.0.2)
#>    foreach               1.5.1     2020-10-15 [1] CRAN (R 4.0.3)
#>    foreign               0.8-80    2020-05-24 [2] CRAN (R 4.0.3)
#>    fs                    1.5.0     2020-07-31 [1] CRAN (R 4.0.2)
#>    furrr                 0.2.1     2020-10-21 [1] CRAN (R 4.0.2)
#>    future                1.21.0    2020-12-10 [1] CRAN (R 4.0.3)
#>    gargle                0.5.0     2020-05-06 [1] CRAN (R 4.0.2)
#>    generics              0.1.0     2020-10-31 [1] CRAN (R 4.0.3)
#>    ggdendro              0.1.22    2020-09-13 [1] CRAN (R 4.0.2)
#>    ggplot2             * 3.3.3     2020-12-30 [1] CRAN (R 4.0.3)
#>    ggpubr                0.4.0     2020-06-27 [1] CRAN (R 4.0.2)
#>    ggrepel               0.9.0     2020-12-16 [1] CRAN (R 4.0.3)
#>    ggsignif              0.6.0     2019-08-08 [1] CRAN (R 4.0.2)
#>    glmnet                4.1       2021-01-11 [1] CRAN (R 4.0.3)
#>    globals               0.14.0    2020-11-22 [1] CRAN (R 4.0.3)
#>    glue                  1.4.2     2020-08-27 [1] CRAN (R 4.0.2)
#>    googledrive           1.0.1     2020-05-05 [1] CRAN (R 4.0.2)
#>    gridExtra             2.3       2017-09-09 [1] CRAN (R 4.0.2)
#>    gtable                0.3.0     2019-03-25 [1] CRAN (R 4.0.2)
#>    haven                 2.3.1     2020-06-01 [1] CRAN (R 4.0.2)
#>    highr                 0.8       2019-03-20 [1] CRAN (R 4.0.2)
#>    hms                   1.0.0     2021-01-13 [1] CRAN (R 4.0.3)
#>    htmltools             0.5.1     2021-01-12 [1] CRAN (R 4.0.3)
#>    httpuv                1.5.5     2021-01-13 [1] CRAN (R 4.0.3)
#>    httr                  1.4.2     2020-07-20 [1] CRAN (R 4.0.2)
#>    iterators             1.0.13    2020-10-15 [1] CRAN (R 4.0.3)
#>    jsonlite              1.7.2     2020-12-09 [1] CRAN (R 4.0.3)
#>    knitr                 1.30      2020-09-22 [1] CRAN (R 4.0.2)
#>    labeling              0.4.2     2020-10-20 [1] CRAN (R 4.0.3)
#>    later                 1.1.0.1   2020-06-05 [1] CRAN (R 4.0.2)
#>    lattice               0.20-41   2020-04-02 [2] CRAN (R 4.0.3)
#>    LDAvis                0.3.2     2015-10-24 [1] CRAN (R 4.0.2)
#>    lgr                   0.4.2     2021-01-10 [1] CRAN (R 4.0.3)
#>    LiblineaR             2.10-8    2017-02-13 [1] CRAN (R 4.0.0)
#>    lifecycle             0.2.0     2020-03-06 [1] CRAN (R 4.0.2)
#>    listenv               0.8.0     2019-12-05 [1] CRAN (R 4.0.2)
#>    lubridate             1.7.9.2   2020-11-13 [1] CRAN (R 4.0.3)
#>    magrittr              2.0.1     2020-11-17 [1] CRAN (R 4.0.3)
#>    MASS                  7.3-53    2020-09-09 [2] CRAN (R 4.0.3)
#>    Matrix                1.2-18    2019-11-27 [2] CRAN (R 4.0.3)
#>    mlapi                 0.1.0     2017-12-17 [1] CRAN (R 4.0.2)
#>    modelr                0.1.8     2020-05-19 [1] CRAN (R 4.0.2)
#>    munsell               0.5.0     2018-06-12 [1] CRAN (R 4.0.2)
#>    network               1.16.1    2020-10-07 [1] CRAN (R 4.0.3)
#>    openssl               1.4.3     2020-09-18 [1] CRAN (R 4.0.2)
#>    openxlsx              4.2.3     2020-10-27 [1] CRAN (R 4.0.3)
#>    parallelly            1.23.0    2021-01-04 [1] CRAN (R 4.0.3)
#>    pillar                1.4.7     2020-11-20 [1] CRAN (R 4.0.3)
#>    pkgconfig             2.0.3     2019-09-22 [1] CRAN (R 4.0.2)
#>    promises              1.1.1     2020-06-09 [1] CRAN (R 4.0.2)
#>    proxy                 0.4-24    2020-04-25 [1] CRAN (R 4.0.2)
#>    proxyC                0.1.5     2019-07-21 [1] CRAN (R 4.0.2)
#>    purrr               * 0.3.4     2020-04-17 [1] CRAN (R 4.0.2)
#>    quanteda              2.1.2     2020-09-23 [1] CRAN (R 4.0.2)
#>    quanteda.textmodels   0.9.2     2020-12-11 [1] CRAN (R 4.0.3)
#>    R.cache               0.14.0    2019-12-06 [1] CRAN (R 4.0.2)
#>    R.methodsS3           1.8.1     2020-08-26 [1] CRAN (R 4.0.2)
#>    R.oo                  1.24.0    2020-08-26 [1] CRAN (R 4.0.2)
#>    R.utils               2.10.1    2020-08-26 [1] CRAN (R 4.0.2)
#>    R6                    2.5.0     2020-10-28 [1] CRAN (R 4.0.3)
#>    Rcpp                  1.0.6     2021-01-15 [1] CRAN (R 4.0.3)
#>    RcppKagome            0.0.0.500 2021-01-20 [1] local         
#>  D RcppParallel          5.0.2     2020-06-24 [1] CRAN (R 4.0.2)
#>    RcppProgress          0.4.2     2020-02-06 [1] CRAN (R 4.0.2)
#>    readr               * 1.4.0     2020-10-05 [1] CRAN (R 4.0.3)
#>    readtext              0.80      2020-09-22 [1] CRAN (R 4.0.2)
#>    readxl                1.3.1     2019-03-13 [1] CRAN (R 4.0.2)
#>    reprex                0.3.0     2019-05-16 [1] CRAN (R 4.0.2)
#>    RhpcBLASctl           0.20-137  2020-05-17 [1] CRAN (R 4.0.0)
#>    rio                   0.5.16    2018-11-26 [1] CRAN (R 4.0.2)
#>    RJSONIO               1.3-1.4   2020-01-15 [1] CRAN (R 4.0.0)
#>    rlang                 0.4.10    2020-12-30 [1] CRAN (R 4.0.3)
#>    rle                   0.9.2     2020-09-25 [1] CRAN (R 4.0.3)
#>    rmarkdown             2.6       2020-12-14 [1] CRAN (R 4.0.3)
#>    rsparse               0.4.0     2020-04-01 [1] CRAN (R 4.0.2)
#>    RSpectra              0.16-0    2019-12-01 [1] CRAN (R 4.0.2)
#>    rstatix               0.6.0     2020-06-18 [1] CRAN (R 4.0.2)
#>    rstudioapi            0.13      2020-11-12 [1] CRAN (R 4.0.3)
#>    Rtsne                 0.15      2018-11-10 [1] CRAN (R 4.0.2)
#>    rtweet                0.7.0     2020-01-08 [1] CRAN (R 4.0.2)
#>    rvest                 0.3.6     2020-07-25 [1] CRAN (R 4.0.2)
#>    scales                1.1.1     2020-05-11 [1] CRAN (R 4.0.2)
#>    servr                 0.21      2020-12-14 [1] CRAN (R 4.0.3)
#>    sessioninfo           1.1.1     2018-11-05 [1] CRAN (R 4.0.2)
#>    shape                 1.4.5     2020-09-13 [1] CRAN (R 4.0.2)
#>    sna                   2.6       2020-10-06 [1] CRAN (R 4.0.3)
#>    SparseM               1.78      2019-12-13 [1] CRAN (R 4.0.0)
#>    statnet.common        4.4.1     2020-10-03 [1] CRAN (R 4.0.3)
#>    stopwords             2.1       2020-12-08 [1] CRAN (R 4.0.3)
#>    stringi               1.5.3     2020-09-09 [1] CRAN (R 4.0.2)
#>    stringr             * 1.4.0     2019-02-10 [1] CRAN (R 4.0.2)
#>    styler                1.3.2     2020-02-23 [1] CRAN (R 4.0.2)
#>    survival              3.2-7     2020-09-28 [2] CRAN (R 4.0.3)
#>    text2vec              0.6       2020-02-18 [1] CRAN (R 4.0.2)
#>    textmineR             3.0.4     2019-04-18 [1] CRAN (R 4.0.2)
#>    tibble              * 3.0.5     2021-01-15 [1] CRAN (R 4.0.3)
#>    tidyr               * 1.1.2     2020-08-27 [1] CRAN (R 4.0.2)
#>    tidyselect            1.1.0     2020-05-11 [1] CRAN (R 4.0.2)
#>    tidyverse           * 1.3.0     2019-11-21 [1] CRAN (R 4.0.2)
#>    usethis               2.0.0     2020-12-10 [1] CRAN (R 4.0.3)
#>    utf8                  1.1.4     2018-05-24 [1] CRAN (R 4.0.2)
#>    vctrs                 0.3.6     2020-12-17 [1] CRAN (R 4.0.3)
#>    viridis               0.5.1     2018-03-29 [1] CRAN (R 4.0.2)
#>    viridisLite           0.3.0     2018-02-01 [1] CRAN (R 4.0.2)
#>    withr                 2.4.0     2021-01-16 [1] CRAN (R 4.0.3)
#>    xfun                  0.20      2021-01-06 [1] CRAN (R 4.0.3)
#>    xml2                  1.3.2     2020-04-23 [1] CRAN (R 4.0.2)
#>    yaml                  2.2.1     2020-02-01 [1] CRAN (R 4.0.0)
#>    zip                   2.1.1     2020-08-27 [1] CRAN (R 4.0.2)
#> 
#> [1] C:/Users/user/Documents/R/win-library/4.0
#> [2] C:/Program Files/R/R-4.0.3/library
#> 
#>  D -- DLL MD5 mismatch, broken installation.
```

